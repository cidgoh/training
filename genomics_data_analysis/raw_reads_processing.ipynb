{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "354ca6e6-eb53-4957-b4da-b6a7f2040991",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "**Last updated:** September 2023\n",
    "\n",
    "Throughout these tutorials we want to introduce some of the common tools used in our laboratory, the **Center for Infectious Disease Genomics and One Health**, for analysis of bacterial sequencing data. \n",
    "\n",
    "As bioinformatics  is a rapidly changing field, the pipelines and software used may change over time or become obsolete. New trainees will be in charge of reproducing the pipeline format and evaluating the content. \n",
    "\n",
    "## Before starting\n",
    "\n",
    "### Disclaimer: updating the notebook\n",
    "\n",
    "Please update the tools and information in thi Jupyter notebook if you realize that there is a new version or a more appropriate procedure. Also feel free to add new content by forking and modifying the file, to keep track of changes, please do a **pull request** to the base repository. \n",
    "\n",
    "### Pre-requisites\n",
    "\n",
    "These tutorials assume that you have a basic understanding of the process behind producing next generation sequencing reads, as we start with data already sequenced. Also, you should be familiar with the command line, at least how to move around different folders and having a basic grasp of commonly used commands and regular expressions. \n",
    "\n",
    "If you have not interacted before with the command line or have limited experience, we would recommend you to take a look at the resources below:\n",
    "\n",
    "- Software carpentry foundation: guided tutorial introducing the command line : [The Unix Shell](https://swcarpentry.github.io/shell-novice/)\n",
    "- [Extra Unix Shell Material from Software Carpentry](https://carpentries-incubator.github.io/shell-extras/): includes additional set up options and describes advanced commands such as `awk` and use of aliases.\n",
    "- Bioinformatics Workbook by Andrew Severin has a text based introduction of how to set up a shell(command line) for many systems: [Unix Basics] (https://bioinformaticsworkbook.org/Appendix/Unix/unix-basics-1.html#gsc.tab=0)\n",
    "- Happy Belly Informatics maintained by Mike Lee (AstroBioMike) has several tutorials ([link here](https://astrobiomike.github.io/all_tutorials/)) about the unix command line and Bioinformatics pipelines \n",
    "\n",
    "It is not necessary to be familiar with software containers, although you may find it helpful for your later work. You can find additional information in this [Carpentries introduction to Singularuity containers](https://carpentries-incubator.github.io/singularity-introduction/). \n",
    "\n",
    "Finally, this is a Jupyter notebook and it would be helpful to have a basic notion of how it works and how to modify it, you can find more information about what is a Jupyter notebook here: https://docs.jupyter.org/en/latest/. The minimum resource you should take a look before digging into the tutorials is [this practical introduction](https://docs.jupyter.org/en/latest/start/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3447a239-25e7-4b7f-80ee-943955ae1d63",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Required tools\n",
    "\n",
    "After a sequencing experiment, the data is available as reads (representations of sections of nucleotides) and typically available in [fastq](https://en.wikipedia.org/wiki/FASTQ_format) format. The length of the reads and the quality of the assigned nucleotides depends largely on the processing steps and the technology used (Illumina, Nanopore, PacBio).\n",
    "\n",
    "Most of our analysis are done in a High Performance Computing cluster as most tools are resource intensive and performing analysis on your local computer would be too time consuming. The currently used cluster is **Compute Canada (CC cluster)**, you can login using the instructions available in the [wiki page for new users](https://docs.alliancecan.ca/wiki/SSH). \n",
    "\n",
    "In the **CC cluster**, there are several tools already available to be used as modules. This environment (computing system) has reproduced this setup and you can use a similar command to load software. `module load desired_software/version`\n",
    "\n",
    "Manually installing tools can create conflicts and errors. Thus, we will use containers (ready to use packages with necessary environment for a tool). Singularity containers are executed using the command `singularity run tool_image` or `singularity exec tool_image command`. There is no need to download said containers as they should be readily available once you connect to this server. See below how we use `singularity` to execute multiqc at the end of this tutorial.\n",
    "\n",
    "Tools used in this section:\n",
    "- `seqkit   v2.3.1`\n",
    "- `fastqc   v0.11.9`\n",
    "- `BBtools  v38.36`\n",
    "- `multiqc  v1.14`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86568dc1",
   "metadata": {},
   "source": [
    "## Preparing the environment\n",
    "\n",
    "### Select interpreter for Jupyter notebook\n",
    "\n",
    "Kernels are programs that mimic operating systems. In jupyter, they tell the system what king of programming language should be interpreted. \n",
    "\n",
    "In order to run these notebooks, a pre-built environment was developed and we are using bash/shell commands. So make sure to load the **bash_kernel/bash** in the upper right corner of the notebook. \n",
    "\n",
    "### Load additional software pre-packaged in the environment\n",
    "\n",
    "The `source` command imports a script and executes it. As we are running the command line from inside the Jupyter notebook, it does not have all the functionality of our [high-performance cluster](https://www.hpc.iastate.edu/guides/introduction-to-hpc-clusters/what-is-an-hpc-cluster) by default (Compute Canada/Digital Research Alliance). \n",
    "\n",
    "Most HPC have pre-loaded software installed, and you can make it available for your session using the `module` command; with this line we make the same resources available to us during the tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f6cda3",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# source PATH to use module function\n",
    "source /cvmfs/soft.computecanada.ca/config/profile/bash.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ee6e61",
   "metadata": {},
   "source": [
    "### Environment structure\n",
    "\n",
    "We will first explore the structure of our environment and the folders available. It is good practice to assign a directory (`tutorials`) to every project. Inside this main directory, we will create subdirectories with results, analysis instructions, and tools necessary for analysis.\n",
    "\n",
    "Every command can be explored using `command --help` for further details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8e7199-91e4-42c7-a4ff-6d993e6d1aa8",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# create a tutorials folder for all results\n",
    "mkdir -p $HOME/tutorials\n",
    "\n",
    "echo -e \"The path to your home directory is\n",
    "$(realpath $HOME)\"\n",
    "\n",
    "echo -e \"\n",
    "Take a look at the folder containing software/data for the tutorials:\"\n",
    "tree -dL 2 /mnt/cidgoh-object-storage/seagull/jupyter-mdprieto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916d8964-9dc9-4ace-9491-1b7d3c3e0f3f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exploring the data\n",
    "\n",
    "Datasets for this tutorial are available in a shared folder inside the `tutorials` directory called `raw_reads`. These are Illumina technology short read sequences from a biological data repository (75bp paired end reads). The isolates were cultured to investigate an outbreak of multi-drug resistant _Pseudomonas aeruginosa_ in Switzerland [PMID:34412676](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8376114/). To make it faster and easier to run, we use a subset of 10 bacterial isolates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96367ca-ca0d-4e18-b1f1-40bb00ec9aa5",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# show content of raw_reads directory\n",
    "ls -1 /mnt/cidgoh-object-storage/seagull/jupyter-mdprieto/raw_reads_tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c947fa3-6a3c-4b56-86eb-f3c3b1a07a1d",
   "metadata": {},
   "source": [
    "These reads are compressed (extension .gz), but most bioinformatic programs can receive `.tar` or `.gzip` files as input. To unzip, the command is `tar -zxf file(s)_to_decompress`.\n",
    "\n",
    "The fastq files have the naming convention `_R1.fastq` or `_R2.fastq` for every isolate because we are using paired-end reads (segments of the DNA are analyzed from both ends, left and right). Other naming structures can be used to represent paired end reads (`_1.fastq, _R001.fastq`). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f3c59f-2d7d-4fd2-81a5-9a21a19a04f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Quality control\n",
    "\n",
    "It is a good practice to organize preliminary results in their own directory so you can trace back when necessary. You can also use github repositories to track all changes related to a project. \n",
    "\n",
    "We will create a new directory for output `tutorials/results` and another subdirectory for this particular step `tutorials/results/reads_qc`. \n",
    "\n",
    "<font color='darkred'>_**Notes for compute canada:**_ </font>  \n",
    "- Compute Canada provides different directories for storage. Jobs cannot be launched from the *HOME* and *PROJECT* directory or any of its subdirectories. The ideal place to run jobs is the *SCRATCH* folder, where you have short term storage of large amounts of data. \n",
    "- Once you have final results, these should be moved to your *PROJECT* directory as the *SCRATCH* folder is constantly being cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77ddec4-742e-4678-ba62-d23ff92d9f69",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# creates new directory for results of QC \n",
    "mkdir -p $HOME/tutorials/results/raw_seqkit\n",
    "\n",
    "# show our new project structure\n",
    "tree -dL 2 $HOME/tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a6ce3d-9711-43f4-9350-22348740fd87",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Basic statistics of reads with Seqkit \n",
    "\n",
    "***seqkit*** summarizes quality statistics (scores for each assigned nucleotide and length diversity) of all reads in a a folder into a text file. basic statistics from the **.fastq** files. \n",
    "\n",
    "To make the software available to us, we can use the functionality `module` that we made available in the preparation section. More information about how to use modules can be found in the [Digital Research Alliance Canada wiki](https://docs.alliancecan.ca/wiki/Utiliser_des_modules/en). \n",
    "\n",
    "The basic syntax for any software/module is `module load module_dependency desired_module`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd062d2e-81f5-4c70-bc3c-2963fc60015e",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# load seqkit and dependencies to our computing environment\n",
    "module load StdEnv/2020 seqkit/2.3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3a1db4",
   "metadata": {},
   "source": [
    "In the command line, when we want to run a command that involves a file, we have to move to the specific directory and run the desired command or include the complete path to said file (/mnt/source/user/...). \n",
    "\n",
    "To avoid extra typing, we can create variables (**environment variables**) that store this path and reuse them sparingly. You can learn more about the use of environment variables in linux environments in the following link: [ENVIRONMENT VARIABLES](https://linuxize.com/post/how-to-set-and-list-environment-variables-in-linux/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2731658c-c3bf-4bed-a232-5cf5db7407bf",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# create environment variables to avoid typing PATHs every time\n",
    "RAW_READS=\"/mnt/cidgoh-object-storage/seagull/jupyter-mdprieto/raw_reads_tutorial\"\n",
    "RESULTS_SEQKIT=\"$HOME/tutorials/results/raw_seqkit\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57581ffd-9b41-4467-8a5e-37c3e856a462",
   "metadata": {},
   "source": [
    "Then, we run the`seqkit` command and preview the text file that summarizes the results . The wait time for output should be around minute only as this is not a demanding process.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2104d57-6c43-4b81-b9b3-4befd047c623",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# run sequence statistics\n",
    "seqkit stats $RAW_READS/*.fastq.gz > $RESULTS_SEQKIT/seqkit_output.tsv\n",
    "\n",
    "# check results\n",
    "head $RESULTS_SEQKIT/seqkit_output.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a2d7e8-1dcd-4e15-9336-e02f8e680cf0",
   "metadata": {},
   "source": [
    "## 2. Trimming reads with BBtools\n",
    "\n",
    "This step is not mandatory because many genome assemblers can remove sequencing adapters from the raw reads before trying to produce a complete genome. \n",
    "\n",
    "However, it is always recommended to filter out poor quality sequences and guarantee the quality of the starting data. The command removes adaptor sequences and any reads with poor quality over a moving window of 21 basepairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d246bb-cdcd-4529-9e93-af54e1f28702",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "module load StdEnv/2020 bbmap/38.86"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f175453f-f02b-4295-8bb7-c006a5f55b75",
   "metadata": {},
   "source": [
    "The tool includes a text file with commonly used adaptor sequences for the **Illumina** platform. The process removes any reads from our sequencing files that match these reference sequences (fasta format). \n",
    "\n",
    "The command used is `bbduk.sh` and we add several options:\n",
    "\n",
    "- Specify `PATHs` to adapter sequences file and to output directory for trimmed reads\n",
    "- `k=23`    - specifies the size of the moving window for quality control of reads\n",
    "- `trimq=6` - removes regions with a score of quality below 6\n",
    "- `tbo`     - Trim adapters based on where paired reads overlap\n",
    "- `tpe`     - When kmer right-trimming, trim both reads to the minimum length of either"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d12e3e-1b41-4d2e-8b6c-bfdd9fc5a582",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# establish necessary paths\n",
    "ADAPTERS='/mnt/cidgoh-object-storage/seagull/jupyter-mdprieto/reference_data/adapters.fa'\n",
    "TRIMMED_READS=\"$HOME/tutorials/trimmed_reads\"\n",
    "RAW_READS=\"/mnt/cidgoh-object-storage/seagull/jupyter-mdprieto/raw_reads_tutorial\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2738c124-b2e4-48ea-ae0a-bee192454d9d",
   "metadata": {},
   "source": [
    "After defining additional environment variables to minimize our typing, we create a for loop to execute the same command (in this case `bbduk.sh`) for every sample available. It takes around 5 minutes to run as we only have 10 samples.\n",
    "\n",
    "If you want to learn more about the use of for loops in bioinformatics, make sure to review the suggested tutorials for the shell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a264208d-19e2-4d4c-9cf7-37c67981c135",
   "metadata": {
    "scrolled": true,
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "for i in $(ls $RAW_READS/*_R1*)     \n",
    "do\n",
    "R1=$(basename $i)                                                                               `# save the filename of read_1 in a variable called R1`\n",
    "R2=$(echo $R1 | sed 's/_R1/_R2/')                                                               `# specify the matching read_2 in variable R2`                                                                \n",
    "bbduk.sh \\\n",
    "    in1=$RAW_READS/$R1 in2=$RAW_READS/$R2                                                       `# define read_1 and read_2 as inputs` \\\n",
    "    out1=$TRIMMED_READS/$R1 out2=$TRIMMED_READS/$R2                                             `# output trimmed reads with same name in trimmed_reads folder` \\\n",
    "    ref=$ADAPTERS                                                                               `# specify the adaptor sequence for matching` \\\n",
    "    k=23 \\\n",
    "    trimq=6 \\\n",
    "    tpe \\\n",
    "    tbo \\\n",
    "    threads=9\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78da278-281e-4306-89d2-f218fad0ab75",
   "metadata": {},
   "source": [
    "**Ouput of trimming** can be seen in the `trimmed_reads` folder as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef4ea0e-e58d-4f23-b0ef-80990f67117c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ls -1 $HOME/tutorials/trimmed_reads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad585f73-2688-4442-88d6-0fdb38095254",
   "metadata": {},
   "source": [
    "## 3. fastqc\n",
    "\n",
    "We will use **fastqc**  to create additional metrics of sequencing including nucleotide distribution, presence of repeats, quality of base calling, GC content and adapter content. \n",
    "\n",
    "The outputs will be produced in new subdirectories of `results` called **raw_fastqc/trimmed_fastqc**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2b7d58-3172-4b50-93d8-dbdd303a309e",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# create output directories\n",
    "mkdir -p $HOME/tutorials/results/raw_fastqc\n",
    "mkdir -p $HOME/tutorials/results/trimmed_fastqc\n",
    "\n",
    "# define environment variables\n",
    "FASTQC_RAW=\"$HOME/tutorials/results/raw_fastqc\"\n",
    "FASTQC_TRIMMED=\"$HOME/tutorials/results/trimmed_fastqc\"\n",
    "\n",
    "# load the fastqc tool\n",
    "module load StdEnv/2020 fastqc/0.11.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7b3daf-9e0c-4828-b737-6b6855e62a4b",
   "metadata": {},
   "source": [
    "- I input all the files that have the suffix 'fastq.gz' from our **raw reads** directory and specify that 10 files will be processed simultaneously (`-t 10`). \n",
    "    - The processing should take around 3 minutes for this set of 10 samples. \n",
    "- Then, we do the same analysis but with the **trimmed_reads** to see if pre-processing improved the quality of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96460c65-f714-40a7-a06c-14c909951062",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fastqc $RAW_READS/*.fastq.gz \\\n",
    "    -o $FASTQC_RAW \\\n",
    "    -t 10 \\\n",
    "    --quiet\n",
    "    # output is saved as individual files in READS_QC_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754a5266-01fa-4eec-a52a-f0616750ae59",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "fastqc $TRIMMED_READS/*.fastq.gz \\\n",
    "    -o $FASTQC_TRIMMED \\\n",
    "    -t 10 \\\n",
    "    --quiet\n",
    "    # output is saved as individual files in READS_QC_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4da92e-ea3f-4e2c-90dd-cd3ce72f400b",
   "metadata": {},
   "source": [
    "\n",
    "- We can list all files in the output directory of **fastqc**, the default command creates `zip` and `html` files for every read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6921c08e-1d79-42b9-873a-94d3081b1f1b",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "echo -e \"\\nRAW READS:\"\n",
    "ls $FASTQC_RAW | head \n",
    "\n",
    "echo -e \"\\nTRIMMED READS:\"\n",
    "ls $FASTQC_TRIMMED | head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbba17a-dc76-487b-9832-65ee6eea1fff",
   "metadata": {},
   "source": [
    "\n",
    "We can also see that we have added several new folders in an organized way to our tutorials/results folder, take a look with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d8aae4-12e0-4c1b-925f-b952ba0f8d00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "echo -e \"Updated tutorials folder structure:/n\"\n",
    "tree -d $HOME/tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d57a75-e748-440f-907d-e388c8933e56",
   "metadata": {},
   "source": [
    "## 4. Summarize with multiqc\n",
    "Finally, **multiqc** is a really useful tool that can summarize all quality control output into a single html file.\n",
    "\n",
    "With the code below, we summarize all **fastqc** output contained in the `reads_qc` results directory. The output can be visualized using any web browser. \n",
    "\n",
    "Once again, the tool is available as a singularity container and is called using `singularity exec PATH/TO/IMAGE multiqc qc_directory`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803fd80c-efc5-4845-9ad1-7148f0075c55",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "singularity exec /mnt/cidgoh-object-storage/images/multiqc_1.14.img multiqc $FASTQC_RAW \\\n",
    "    -f \\\n",
    "    -o $FASTQC_RAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b8c0fa-a126-4ede-88c8-ad708261c977",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "singularity exec /mnt/cidgoh-object-storage/images/multiqc_1.14.img multiqc $FASTQC_TRIMMED  \\\n",
    "    -f \\\n",
    "    -o  $FASTQC_TRIMMED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20711b22-9f8f-424e-a2c9-163fe00085cd",
   "metadata": {},
   "source": [
    "\n",
    "`multiqc` produces an `.html` file with several visualizations, you can download it to your own computer and explore it in a web browser (chrome, mozilla, edge). \n",
    "If you are using the Jupyter environment (Graphical User Interface) you can navigate the folders to the location of the files (`$HOME/tutorials/results/raw_fastqc/multiqc_report.html`) and open it manually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2368c0-5882-44a9-b0f6-91522425f187",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "## Pipeline script for Compute Canada (REFERENCE ONLY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5929e8bd-4344-42cb-96be-4351fed670b4",
   "metadata": {},
   "source": [
    "In compute canada, we run intensive commands as part of jobs. In a job, we specify how much memory and processing power we require and the system will automatically asign these values and run our specified commands. \n",
    "\n",
    "To do this, we save all of our commands and the instructions for the job in a text file. To do this, we open a text editor (`nano text_filename` or `vim text_filename`) and copy the following commands.\n",
    "Once the commands are written in the text, we save the file using **Ctrl+X** in `nano` or **Esc + ZZ** in `vim`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c6e8a9-f4c3-4ba3-b64b-4260ac717efa",
   "metadata": {},
   "source": [
    "```\n",
    "#!/bin/bash\n",
    "#SBATCH --account=rrg-whsiao-ab                    # compute canada PI allocation\n",
    "#SBATCH --mem=25gb                                 # 25 GB of memory\n",
    "#SBATCH --time=06:00:00                            # approximate time to complete all actions\n",
    "#SBATCH --job-name=\"quality_control\"               # name of job\n",
    "#SBATCH --chdir=/scratch/mdprieto/tutorials        # change to directory before start\n",
    "#SBATCH --cpus-per-task=9                          # number of threads, how many simultaneous tasks\n",
    "export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "\n",
    "################################ preparation ######################################\n",
    "\n",
    "# load necessary modules\n",
    "module load StdEnv/2020 bbmap/38.86 fastqc/0.11.9 seqkit/0.15.0 \n",
    "\n",
    "# create output directory\n",
    "mkdir -p ~/tutorials/qc_results\n",
    "\n",
    "# establish path for outputs and input\n",
    "adapters_file='PATH/TO/adapters.fa'\n",
    "OUTPUT_QC=\"$HOME/tutorials/results_qc\"\n",
    "OUTPUT_TRIM=\"$HOME/tutorials/trimmed_reads\"\n",
    "INPUT_DIR=\"PATH/TO/raw_reads\"\n",
    "\n",
    "################################## seqkit #########################################\n",
    "\n",
    "# run seqkit in fastq file and save output in tab separated file\n",
    "seqkit stats $INPUT_DIR/*.fastq.gz > $OUTPUT_QC/seqkit_output.tsv\n",
    "\n",
    "################################## fastqc #########################################\n",
    "\n",
    "# for all files in raw_reads directory\n",
    "fastqc $INPUT_DIR/*.fastq.gz \\\n",
    "    -o $OUTPUT_QC \\\n",
    "    -t 9 \\\n",
    "    --quiet\n",
    "\n",
    "################################## multiqc #########################################\n",
    "\n",
    "# execute from singularity\n",
    "singularity exec $HOME/tools/multiqc_1.14.sif multiqc $OUTPUT_QC\n",
    "\n",
    "################################## trimming ########################################\n",
    "\n",
    "for i in $(ls $INPUT_DIR/*_R1*)\n",
    "do\n",
    "R1=$(basename $i)\n",
    "R2=$(echo $R1 | sed 's/_R1/_R2/')\n",
    "bbduk.sh \\\n",
    "    in1=$INPUT_DIR/$R1 in2=$INPUT_DIR/$R2 \\\n",
    "    out1=$OUTPUT_TRIM/$R1 out2=$OUTPUT_TRIM/$R2 \\\n",
    "    ref=$adapters_file \\\n",
    "    k=23 trimq=6 tpe tbo \\\n",
    "    threads=9\n",
    "done\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462e363f-a5c8-4b02-b313-c8e915bb9099",
   "metadata": {},
   "source": [
    "### <font color='darkred'>_**Notes for compute canada**_ </font>  \n",
    "Our pipeline for quality control of raw reads includes several steps:\n",
    "\n",
    "1. We use the ***seqkit*** tool to obtain basic statistics from the **.fastq** files. The module to load **seqkit** is available in CC, so it can be load using `module load`. \n",
    "    - The tool takes `fastq` files as inputs and produces a txt output \n",
    "2. We will use **fastqc** which is also available as a module in ComputeCanada. The tool creates an overall summary of different metrics of sequencing including nucleotide distribution, presence of repeats, quality of base calling, GC content and adapter content\n",
    "    - **fastqc** produces an output summary for every file entered\n",
    "3. Another tool (**multiqc**) takes all output summaries of **fastqc** in a directory and creates a nice single HTML output that can be visualized in any web browser.\n",
    "    - Not available in Compute Canada, so we use a singularity container to execute it\n",
    "4. To have reads ready for assembly, I trimm or remove any PCR adaptors, barcodes or poor quality regions using **BBtools**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
